# 20190807

## HDFS(Hadoop Distributed File System)

하둡 분산파일 시스템

##### 하둡 전까지

- DAS : 서버와 연결된 외장형 하드(여러개)
- NAS : 파일 서버(별도의 OS가 들어가고, 파일 시스템을 안정적으로 공유할 수 있음)
- SAN : 별도의 데이터 서버 

위의 것들에 비해 Hadoop의 장점 : 저사양 서버를 이용해 스토리지를 구성할 수 있음

기존의 시스템은 중앙집중식이라 중앙에 쓰일 고성능 서버를 써야한다. 하지만 HDFS는 여러개의 웹 서버급의 저사양 서버를 사용해서 스토리지를 만들 수 있다.

하지만 아직 

고신용도 ,빠른 복구를 위해서는 SAN을, 전자상거래처럼 트랜잭션(속도, 원자성, 멀티 태스킹?)이 중요한 경우 

### 하둡의 목표

##### 장애 복구

장애를 빠른 시간에 감지하고, 대처할수 있다. 분산 서버간에 주기적으로 상태를 체크해 빠른 시간에 장애를 인지, 대처할 수 있게 도와준다.

##### 스트리밍 방식의 데이터 접근

동일한 시간 내에 더 많은 데이터를 처리하는 것을 목표로 한다.

##### 대용량 데이터 저장



##### 데이터 무결성

한번 저장된 데이터는 수정할 수 없다. 읽기, 이동, 삭제, 복사를 할수 있음(overwrite는 가능)

하둡 2.0에서는 기존 내용의 수정은 불가하지만, 문서의 끝에 문장을 추가하는 append는 지원



### HDFS 아키텍쳐

#### 블록 구조 파일 시스템

파일은 특정 크기의 블록으로 나눠서 분산된 서버에 저장

블록의 크기는 기본값이 64MB이고, 사용자가 바꿀수 있음

※ 왜 64MB인가

* 디스크 탐색 시간의 감소 
* 네임노드가 유지하는 메타데이터의 크기 감소 
  * 일반적인 파일 시스템은 블록의 크기가 4k~8K이기 때문에 동일 크기의 파일을 저장할 경우 훨씬 많은 메타데이터가 필요하다.
* 클라이언트와 네임노드의 통신 감소 
  * 클라이언트응 스트리밍 방식으로 데이터를 읽고 쓰기 때문에 통상적으로 네임노드와 통신할 필요가 없다.



#### 네임노드와 데이터 노드

![Apache Hadoop HDFS Architecture - Edureka](https://d1jnx9ba8s6j9r.cloudfront.net/blog/wp-content/uploads/2013/05/Apache-Hadoop-HDFS-Architecture-Edureka.png)

##### 네임노드의 기능

* 메타데이터 관리
* 데이터노드 모니터링
* 블록 관리
* 클라이언트 요청 접수



##### 데이터노드 

* 실제 데이터가 저장된 로우데이터 저장
* 메타데이터가 설정된 파일 저장

※ 스트리밍 방식의 의의 

 1. 클라이언트가 데이터를 요청하면, 네임노드는 클라이언트에게 파일의 위치와 권한을 준다

 2. 클라이언트는 파일이 있는 데이터 노드에 각각(파일이 분산되어 있으므로, 파일의 위치도 여러개) 접근하여 필요한 부분을 받아온다. 

    스트리밍 방식은 한번에 다 가져오는게 아닌, 조각을 가져와서 합치는 방식이므로 

#### HDFS의 파일 저장 

1. 클라이언트의 파일 저장 요청

   ​	네임노드는 클라이언트로부터 요청이 들어오면 파일을 저장하기 위한 스트림을 생성한다.

2. 패킷 전송

   파일 제어권을 얻은 클라이언트는 생성된 스트림을 통해 파일을 데이터노드에 직접(direct) 패킷 단위로 전송한다.

   스트림은 저장이 성공적으로 완료되면 그에 관한 메타데이터를 네임노드에 전송한다.

3. 파일 닫기

   생성된 스트림이 닫힌다.



#### HDFS의 파일 읽기

1. 클라이언트의 파일 읽기 요청

   네임노드는 클라이언트로부터 요청이 들어오면 파일을 읽기 위한 스트림을 생성한다.(스트림에는 파일이 저장된 위치의 블록 index가 저장되어 있다.)

2. 파일 읽기

   스트림에 있는 index의 데이터노드들을 찾아서 각각 데이터(블록)를 가져온다. 

   1. 클라이언트와 블록이 저장된 데이터노드가 같은 서버이 있으면 LocalBlockReader를 생성
   2. 데이터노드가 원격에 있으면 RemoteBlockReader를 생성

3. 파일 닫기

   블록 리더기가 닫히고, 스트림이 제거된다. 

#### 보조네임노드

namenode는 메타데이터를 유지하기위해서 editslog와 fsimage를 생성한다.

editslog는 변경이력을 저장하고, fsimage는 파일시스템의 메타데이터 이미지를 저장한다.

editslog는 변경이력을 쭉 저장하므로, 주기적으로 갱신을 해 줘야하는데, hadoop의 설정에 따라 보조네임노드에서는 editslog의 기록을 바탕으로 fsimage를 갱신하고, editslog를 삭제한다. 

보조네임노드는 네임노드의 fsimage의 갱신을 담당할 뿐, namenode의 백업 서버는 아니다.



### HDFS 명령어

셸 명령어를 지원한다.

셸 명령어는 다음과 같은 형식을 가진다

hadoop fs 명령어 (ex ; hadoop fs -ls)

명령어 목록

- ls , lsr(lsr은 하위 디렉토리까지)
- du, dus(파일의 사용량 ,dus는 전체 합계 용량만)
- cat,text(text는 zip형태도 출력)
- mkdir
- 파일 복사
  - put(로컬 파일 및 디렉토리를 목적지 경로로 복사)
  - copyFromLocal( =put)
  - get(HDFS의 데이터를 로컬파일시스템으로)
  - getmerge(지정된 경로의 모든 파일의 내용을 합친 후, 로컬파일 시스템이 하나로 복사)
- 파일 이동
  - mv
  - moveFromLocal()
- rm(파일 삭제)
- rmr(디렉터리 삭제)
- count
- tail
- 권한 변경
  - chmod
  - chown
  - chgrp
- touchz(크기가 0인 파일 생성)
- stat(통계 정보 조회)
- expunge(휴지통 비우기)
- test(파일 형식 확인 ex: hadoop fs test -ezd   true면 0을 리턴)

## Map Reduce

HDFS에 저장된 파일을 분산 배치 분석을 할수 있게 도와주는 프레임워크이다. 



## HIVE

map reduce를 사용할때 java로 짜는게 아니라, sql문으로 실행하게 해 준다.

#### 설치

1. db(mariadb)를 설치한다.
2. db에 user hive와 db hive_db를 만든다.
3. hive에 접속 권한을 몰아준다
4. hive를 설치한다.
5. hive의 path를 잡아준다.
6. profit!!